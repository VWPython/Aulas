{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints\n",
    "***\n",
    "### Atributos locais e detecção de pontos de interesse em imagens\n",
    "***\n",
    "\n",
    "Até este ponto, consideramos apenas os descritores de imagem que quantificaram toda a imagem - isso nos deixa com uma quantificação global da imagem.\n",
    "\n",
    "No  entanto,  uma  quantificação  global  da  imagem,  o  que  significa  que  cada  pixel  da imagem  está  incluído  na  computação  do  vetor  de  características,  nem  sempre  é  o  mais apropriado.\n",
    "\n",
    "Suponha  que tenhamos  que construir  um  sistema  de  visão computacional para identificar automaticamente as capas de livros. Nosso sistema tira uma foto de uma capa de livro capturada a partir de um dispositivo móvel, como um iPhone ou Android, extrai recursos da imagem e, em seguida, compara os recursos com um conjunto de capas de livros em um banco de dados. Aqui está um exemplo de uma fotografia de capa de livro:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65007960-10573200-d8de-11e9-83cd-b8ed719f4f7d.png)\n",
    "\n",
    "Nosso objetivo aqui é: a partir dessa imagem identificar a capa do livro usando apenas algoritmos de visão computacional. Dado este problema, qual o descritor de imagem que você acha que seria apropriado para esse problema? HOG? LBPs? Haralick texture?\n",
    "\n",
    "O problema com esses descritores é que eles são todos descritores de imagem globais, e se  os  usarmos,  acabaremos  por  quantificar  as  regiões  da  imagem  que  não  nos  interessam, como por exemplo o livro em segundo plano na imagem acima (queremos apenas detectar a capa  do  livro  em  primeiro  plano). Incluir  essas  regiões  em  nossa  computação  de  vetor  de características pode descartar dramaticamente o vetor de características de saída - e corremos o risco de não poder identificar o livro!\n",
    "\n",
    "A solução é usar recursos locais, onde descrevemos apenas pequenas regiões locais da imagem que são consideradas \"interessantes\" em vez de toda a imagem. Essas regiões devem ser únicas, facilmente comparadas e, idealmente, ter algum tipo de significado semântico em relação ao conteúdo da imagem.\n",
    "\n",
    "Como veremos, uma das maiores diferenças entre os descritores de imagem e as nossas contrapartes  de  descritor  de  recursos  locais  é  que  acabaremos  gerando  vários  vetores  de recursos por imagem - um para cada região \"interessante\" de uma imagem.\n",
    "\n",
    "Ao  usar  recursos  locais,  poderemos  alinhar  imagens,  construir  panoramas,  encontrar objetos em imagens e criar aplicativos de aprendizado de máquina mais robustos e poderosos e aplicações de Recuperação de Imagem Baseadas em Conteúdo. Como veremos, os recursos locais são uma ferramenta muito poderosa - mas exigem um pouco mais de processamento e manipulação de nossa parte.\n",
    "\n",
    "#### Atributos Locais\n",
    "\n",
    "Ao nível mais alto, uma \"característica\" é uma região de uma imagem que é única e facilmente reconhecível. Para entender este conceito, vamos começar jogando um pequeno jogo.  Dê  uma  olhada  na  seguinte  imagem,  onde  na  parte  superior  você  encontrará  quatro patches da imagem original:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008089-88bdf300-d8de-11e9-9623-b1fea0612766.png)\n",
    "\n",
    "De onde você acha que esses pacthes vieram? E como você pode ter certeza?\n",
    "\n",
    "Para o Patch A, é muito difícil discernir onde na imagem está localizada - este patch é muito  plano  e  não  contém  cantos,  bordas  ou  texturas  reconhecidas.  Na  verdade,  existem muitas regiões da nossa capa de livro que parecem quase idênticas a este patch. Assim, regiões planas e de baixa densidade não oferecem boas características.\n",
    "\n",
    "Os patches B e C, no entanto, são um pouco mais fáceis de identificar. Essas manchas da imagem obviamente vieram das regiões de borda do livro, em algum lugar perto do teclado do laptop - embora às vezes possa ser difícil identificar exatamente a qual região corresponde uma borda. Por exemplo, se mudássemos a caixa delimitadora de encadernação para cima e para baixo ao longo do limite do livro, as regiões pareceriam bem semelhantes. Assim, as regiões marginais são mais interessantes e discriminativas do que regiões planas, mas ainda podemos melhorar.\n",
    "\n",
    "Finalmente, Patch D é o mais fácil - podemos ver facilmente que esta região é um canto do  livro;  especificamente,  o  canto  inferior  esquerdo,  pois  contém  regiões  da  mão.  Se  você mudasse esta caixa delimitadora para a esquerda ou para a direita, ou para cima e para baixo, o patch  pareceria  bem  diferente.  Os  cantos  são  considerados  regiões  muito  interessantes  e discriminativas para detectar.\n",
    "\n",
    "#### Descrevendo os Patches\n",
    "\n",
    "Então,  agora  que  sabemos  de  onde  as  regiões  da  imagem  vieram,  como  as descrevemos? Nossas descrições podem parecer algo assim:\n",
    "\n",
    "* **Patch A**: Uma região plana e sem textura.\n",
    "\n",
    "\n",
    "* **Patches B e C**: contém uma borda vertical, bordas do livro e o plano de fundo. Contém as teclas de um teclado.\n",
    "\n",
    "\n",
    "* **Patch D**:  O canto inferior esquerdo do livro. Contém parte do livro junto com a mão que está segurando.\n",
    "\n",
    "Assim, onde identificamos regiões potencialmente \"interessantes\" de uma imagem e criamos  uma  descrição  simples  delas,  nossos  algoritmos  de  recursos  locais  em  visão computacional  tentam  encontrar  regiões  interessantes  e  repetidamente  exclusivas  em  uma imagem - seguidas da quantificação da região em torno de cada um desses patches.\n",
    "\n",
    "#### Detecção de Pontos Chave e Extração de Recursos\n",
    "\n",
    "O processo de encontrar e descrever regiões interessantes de uma imagem é dividido em duas fases: detecção de ponto-chave e extração de recursos.\n",
    "\n",
    "A primeira fase é encontrar as regiões \"interessantes\" de uma imagem. Essas regiões podem  ser  bordas,  cantos ou  regiões  de  uma  imagem  onde  as  intensidades  de  pixels  são aproximadamente  uniformes.  Existem  muitos  algoritmos  diferentes  que  estudaremos  que podem encontrar e detectar essas regiões \"interessantes\" - mas, em todos os casos, chamamos essas regiões de interesse de pontos-chave. Os pontos-chave são simplesmente coordenadas (x, y) das regiões de interesse e salientes de uma imagem.\n",
    "\n",
    "Em seguida, para cada um dos nossos pontos-chave, devemos descrever e quantificar a região da imagem em torno do ponto-chave, extraindo um vetor de recursos. Este processo de extração de vários vetores de recursos, um para cada ponto-chave, é chamado de extração de recursos. Novamente, existem muitos algoritmos diferentes que podemos usar para a extração de recursos, e estaremos estudando muitos deles daqui a pouco.\n",
    "\n",
    "No entanto, até este ponto, tivemos uma correspondência um-para-um entre imagens e vetores de recursos. Para cada imagem de entrada, receberíamos um vetor de características. No entanto, agora estamos inserindo uma imagem e recebendo vários vetores de recursos. Se temos vários vetores de recursos para uma imagem, como os comparamos? E como sabemos quais comparar?\n",
    "\n",
    "Conforme descobriremos mais adiante neste curso, a resposta é usar a correspondência de pontos-chave ou o modelo bag-of-visual-words, mas, por enquanto, vamos nos concentrar nos conceitos de extração de pontos-chave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Por que os Keypoints são importantes?\n",
    "***\n",
    "\n",
    "A análise do conteúdo da imagem refere-se ao processo de compreensão do conteúdo de uma imagem para que possamos tomar alguma ação. Vamos dar um passo para trás e falar sobre como os humanos fazem isso. Nosso cérebro é uma máquina extremamente poderosa que  pode  fazer  coisas  complicadas  muito  rapidamente.  Quando  olhamos  para  algo,  nosso cérebro cria automaticamente uma visualização com base nos aspectos \"interessantes\" dessa imagem.\n",
    "\n",
    "Um aspecto interessante é algo distinto em uma região. Se considerarmos um ponto interessante, então não deve haver outro ponto em sua vizinhança que satisfaça as restrições. Vamos considerar a seguinte imagem:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008466-dbe47580-d8df-11e9-8bd2-eeda9aa1b0af.png)\n",
    "\n",
    "Agora feche seus olhos e tente visualizar essa imagem acima. Você vê algo específico? Você consegue lembrar o que está na metade esquerda da imagem? Na verdade, não! A razão para isso é que a imagem não possui informações interessantes. Quando nosso cérebro olha para algo como isso, não há nada a ser observado. Então, ele tende a vagar por aí! Vamos dar uma olhada na seguinte imagem:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008508-fd456180-d8df-11e9-8247-1d9c66e477f1.png)\n",
    "\n",
    "Agora  feche  seus  olhos  e  tente  visualizar  essa  imagem acima.  Você  verá  que  a lembrança é viva e você se lembra de muitos detalhes sobre essa imagem. A razão para isso é que  existem  muitas  regiões  interessantes  na  imagem.  O  olho  humano  é  mais  sensível  ao conteúdo de alta frequência em comparação com o conteúdo de baixa frequência. Esta é a razão  pela  qual  tendemos  a  lembrar  a  segunda  imagem  melhor  do  que  a  primeira.  Para demonstrar isso, vejamos a seguinte imagem:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008548-22d26b00-d8e0-11e9-98ef-7ca05652f30b.png)\n",
    "\n",
    "Se você notar, seu olho imediatamente foi para o controle remoto da TV, mesmo que não esteja no centro da imagem. Nós tendemos automaticamente a gravitar para as regiões interessantes na imagem porque é aí que toda a informação está. Isto é o que nosso cérebro precisa armazenar para se lembrar mais tarde. Quando criamos sistemas de reconhecimento de objetos, precisamos detectar essas regiões \"interessantes\" para criar uma assinatura para a imagem. Essas regiões interessantes são caracterizadas por pontos-chave (keypoints). É por isso que  a  detecção  de  pontos-chave  é  crítica  em  muitos  sistemas  modernos  de  visão computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### O Que SãoKeypoints?\n",
    "***\n",
    "\n",
    "Agora  que  sabemos  que  os  pontos-chave se  referem às  regiões  interessantes  da imagem, vamos ir um pouco mais fundo. Quando dizemos \"interessante\", isso significa que algo está acontecendo nessa região. Se a região é apenas uniforme, então não é muito interessante. Por exemplo, os cantos são interessantes porque há variação acentuada na intensidade em duas direções diferentes. Cada canto é um ponto único onde duas bordas se encontram. Se você  olhar  para  as  imagens  anteriores,  verá  que  as  regiões  interessantes  não  são completamente  constituídas  por  conteúdo  \"interessante\".  Se  você  olhar  de  perto,  ainda podemos ver regiões planas dentro de regiões ocupadas. Por exemplo, considere a seguinte imagem:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008694-96747800-d8e0-11e9-8f2b-ccfab1219e30.png)\n",
    "\n",
    "Se você olhar para o objeto anterior, as partes interiores das regiões interessantes são \"desinteressantes\".\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008943-68dbfe80-d8e1-11e9-8357-cd333fde277a.png)\n",
    "\n",
    "Então, se caracterizássemos esse objeto, precisamos ter certeza de que escolhemos os pontos  interessantes.  Agora,  como  definimos  \"pontos  interessantes\"?  Podemos  dizer  que qualquer coisa que não seja desinteressante pode ser um ponto interessante? Consideremos o seguinte exemplo:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/65008977-8610cd00-d8e1-11e9-8b3b-12a033a4eaf5.png)\n",
    "\n",
    "Agora, podemos ver que há uma grande quantidade de conteúdo de alta frequência nesta imagem ao longo da borda. Mas não podemos chamar a borda inteira \"interessante\". É importante entender que \"interessante\" não se refere necessariamente a valores de cor ou intensidade. Pode ser qualquer coisa, desde que seja distinto. Precisamos isolar os pontos que são únicos em sua vizinhança. Os pontos ao longo da borda não são únicos em relação aos seus vizinhos. Então, agora que sabemos o que estamos procurando, como escolhemos um ponto interessante?\n",
    "\n",
    "E  o  canto  da  mesa?  Isso  é  muito  interessante,  certo?  É  único  em  relação  aos  seus vizinhos e não temos nada parecido na vizinhança. Agora, este ponto pode ser escolhido como um dos nossos pontos-chave. Usamos um monte desses pontos de chave para caracterizar uma imagem  específica.  Quando fazemos  análises  de  imagens,  precisamos  convertê-la  em  uma forma  numérica  antes  de  deduzir  algo.  Esses  pontos-chave  são  representados  usando  uma forma numérica e uma combinação desses pontos-chave é usada para criar a assinatura da imagem.  Queremos que  esta  assinatura  de  imagem  represente  uma  imagem da  melhor maneira possível."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
