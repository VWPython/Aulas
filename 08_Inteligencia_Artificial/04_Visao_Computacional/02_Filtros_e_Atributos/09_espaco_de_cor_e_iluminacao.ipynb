{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de cores e Iluminação da imagem\n",
    "***\n",
    "### Iluminação da Imagem\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O campo da visão computacional está se expandindo e evoluindo rapidamente. Todos os dias estamos vendo novos avanços que pensávamos ser impossíveis. Estamos vendo Deep Learning classificando  imagens  com  uma  precisão  surpreendentemente  alta.  Pequenos computadores, como o Raspberry Pi, podem ser usados para construir sistemas de vigilância usando  visão  computacional.  E  a  indústria  está  vendo  mais  aplicativos  comerciais  de  visão computacional lançados para o mercado todos os dias.\n",
    "\n",
    "E enquanto o campo está crescendo, mudando e evoluindo, podemos garantir algo que provavelmente não mudará: todo algoritmo, aplicação e sistema de visão computacional, já desenvolvido ou que será desenvolvido, dependerá da qualidade das imagens de entrada.\n",
    "\n",
    "Certamente poderemos tornar nossos sistemas mais robustos em relação a condições precárias de iluminação, mas nunca seremos capazes de superar uma imagem capturada em condições  inferiores. A iluminação  pode  significar  a  diferença  entre  sucesso  e  falha  no  seu algoritmo de visão computacional. Não podemos ignorar a iluminação e nem o efeito que terá sobre o desempenho do algoritmo.\n",
    "\n",
    "A qualidade da luz em um determinado ambiente é absolutamente crucial na obtenção de seus objetivos –e provavelmente um dos fatores mais importantes.\n",
    "\n",
    "Para realmente demonstrar esse fato, considere por um segundo como uma câmera captura ou filma um objeto:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64584630-e779ee80-d36b-11e9-86b0-6d7c8e939156.png)\n",
    "\n",
    "A  câmera  não  está  realmente  \"filmando\"  o  próprio  objeto.  Em  vez  disso,  está capturando a luz refletida em nosso objeto. Isso também implica que objetos diferentes em imagens exigirão diferentes condições de iluminação para obter resultados \"bons\" (onde \"bom\" é definido em termos de qualquer objetivo final do seu algoritmo). Em geral, suas condições de iluminação devem ter três objetivos principais:\n",
    "\n",
    "* **Alto contraste**: Maximize  o  contraste  entre  as  Regiões  de  Interesse  na  sua  imagem  (ou  seja,  os \"objetos\"  que  deseja  detectar,  extrair,  descrever  classificar,  manipular,  etc.  devem  ter  um contraste suficientemente alto do resto da imagem para que sejam facilmente detectáveis).\n",
    "\n",
    "\n",
    "* **Generalizável**: Suas condições de iluminação devem ser consistentes o suficiente para que funcionem bem de um \"objeto\" para o próximo. Se nosso objetivo é identificar várias moedas do Brasil em uma  imagem,  nossas  condições  de  iluminação  devem  ser  generalizáveis  o  suficiente  para facilitar a identificação da moeda.\n",
    "\n",
    "\n",
    "* **Estável**: Ter  condições  de  iluminação  estáveis,  consistentes  e  repetitivas  é  o  Santo  Graal  do desenvolvimento de aplicações de visão computacional. No entanto, muitas vezes é difícil (se não impossível) garantir tais condições - isto é especialmente verdadeiro se desenvolvemos algoritmos de visão computacional que se destinem a trabalhar em condições de iluminação exterior. À medida que a hora do dia muda, as nuvens rolam sobre o sol e a chuva começa a derramar, nossas condições de iluminação, obviamente, mudarão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Espaço de Cores\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplificando, um espaço de cores é apenas uma organização específica de cores que nos permite representar e reproduzir cores consistentemente.\n",
    "\n",
    "Um  modelo  de  cor (ou  canal  de  cor), por  outro  lado,  é  um  método  abstrato  de representação  numérica  de  cores  no  espaço  de  cores.  Como  sabemos,  os  pixels  RGB  são representados como uma tupla de 3 inteiros de um valor vermelho, verde e azul.\n",
    "\n",
    "Como  um  todo,  um  espaço  de  cores  define  o  modelo  de  cores  e  a  função  de mapeamento abstrato usado para definir cores reais. Selecionar um espaço de cores também implica informalmente que estamos selecionando o modelo de cores. A diferença entre os dois é sutil, mas importante para cobrir como uma questão de completude.\n",
    "\n",
    "Vamos  discutir  os  quatro  espaços  de  cores  principais  que  você  encontrará  ao desenvolver aplicações de visão computacional: RGB, HSV, L*a*b* e Grayscale (o que não é tecnicamente um espaço de cor, mas você estará usando em quase todas as aplicações de visão computacional que você desenvolver).\n",
    "\n",
    "#### RGB\n",
    "\n",
    "O  primeiro  espaço  de  cores  que  vamos  discutir  é  o  RGB,  que  representa  os componentes vermelho, verde e azul de uma imagem. Para definir uma cor no modelo de cores RGB, tudo o que precisamos fazer é definir a quantidade de Vermelho, Verde e Azul contido em um único pixel. Cada canal vermelho, verde e azul pode ter valores definidos na faixa [0, 255] (para  um  total  de  256  \"tons\"),  onde  0  indica  nenhuma  representação  e  255  demonstra representação total. O espaço de cores RGB é um exemplo de um espaço de cores aditivo: quanto mais de cada cor for adicionada, mais brilhante será o pixel e mais próximo ele será da cor branca:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64584807-a1715a80-d36c-11e9-9884-0c026afa705d.png)\n",
    "\n",
    "A combinação destas 3 cores, nos dará diversas outras cores. Mas perceba como essas variações partem da combinação entre as cores do RGB:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64584829-b6e68480-d36c-11e9-9342-c74dc2207fba.png)\n",
    "\n",
    "Uma vez que uma cor RGB é definida como uma tupla de 3 valores, com cada valor no intervalo  [0,  255],  podemos  assim  pensar  na  combinação  contendo  256  x  256  x  256  = 16,777,216 cores possíveis, dependendo de quanto vermelho, verde e azul colocamos em cada cor. No  entanto,  este  não  é  exatamente  o  espaço  de  cores  mais  amigável  para  o desenvolvimento de aplicações baseadas em visão computacional.\n",
    "\n",
    "#### HSV\n",
    "\n",
    "O espaço de cores HSV transforma o espaço de cores RGB, remodelando-o como um cilindro em vez de um cubo:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64584863-e0071500-d36c-11e9-9893-e1824681f723.png)\n",
    "\n",
    "Como  vimos  na  seção  RGB,  o  \"branco\"  ou  \"leveza\"  de  uma  cor  é  uma  combinação aditiva de cada componente vermelho, verde e azul. Mas agora, no espaço de cores HSV, a leveza tem sua própria dimensão separada. Vamos definir o que cada um dos componentes HSV são:\n",
    "\n",
    "* **Hue**: qual cor \"pura\" que estamos examinando. Por exemplo, todas as sombras e tons da cor \"vermelho\" terão o mesmo matiz.\n",
    "\n",
    "\n",
    "* **Saturação**: quão \"branco\" é a cor. Uma cor totalmente saturada seria \"pura\", como em \"vermelho puro\". E uma cor com zero de saturação seria pura em branco.\n",
    "\n",
    "\n",
    "* **Valor**: o Valor nos permite controlar a leveza de nossa cor. Um valor de zero indicaria preto puro, ao passo que aumentar o valor produziria cores mais claras.\n",
    "\n",
    "É importante notar que diferentes bibliotecas de visão computacional usarão diferentes faixas para representar cada um dos componentes Hue, Saturation e Value.\n",
    "\n",
    "No entanto, no caso do OpenCV, as imagens são representadas como matrizes inteiras não assinadas de 8 bits. Assim, o valor Hue é definido o intervalo [0, 179] (para um total de 180 valores possíveis, uma vez que [0, 359] não é possível para uma matriz não assinada de 8 bits) - o Hue é realmente um grau no cilindro de cor HSV. E a saturação e o valor são definidos na faixa [0, 255].\n",
    "\n",
    "Para converter uma imagem para o espaço de cores HSV, fazemos uma chamada para a função  **cv2.cvtColor** no  OpenCV.  Esta  função aceita  dois  argumentos:  a  imagem  real  que queremos converter, seguida do espaço de cores de saída. Uma vez que o OpenCV representa a nossa  imagem  em  ordem  BGR  em  vez  de  RGB,  especificamos  o  sinalizador **cv2.COLOR_BGR2HSV** para indicar que queremos converter de BGR para HSV.\n",
    "\n",
    "#### L\\*a\\*b\\*\n",
    "\n",
    "Enquanto o espaço de cores RGB é fácil de entender (especialmente quando você está começando  em  visão  computacional),  não  é  intuitivo  ao  definir  tons  exatos  de  uma  cor  ou especificando uma variedade de cores qualquer.\n",
    "\n",
    "Por outro lado, o espaço de cores HSV é mais intuitivo, mas não faz o melhor trabalho para representar a forma como os seres humanos veem e interpretam cores nas imagens. Por exemplo, vamos calcular a distância euclidiana entre as cores vermelha e verde; vermelho e roxo; e vermelho e azul marinho no espaço de cores RGB:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64585026-87844780-d36d-11e9-94df-ec1e397b89ce.png)\n",
    "\n",
    "Então, isso implica a pergunta: o que esses valores de distância realmente representam? A cor vermelha é de alguma forma mais similar ao roxo do que ao verde?\n",
    "\n",
    "A resposta é um simples não - mesmo que tenhamos definido nossos espaços de cores em objetos como um cubo e um cilindro, essas distâncias são realmente bastante arbitrárias e não há nenhuma maneira de \"medir\" a diferença perceptiva em cores entre várias cores nos espaços de cores RGB e HSV.\n",
    "\n",
    "É aí que o espaço de cores L\\*a\\*b\\* entra em ação - o objetivo é imitar a metodologia em que os humanos veeme interpretam a cor. Isso significa que a distância euclidiana entre duas cores arbitrárias no espaço de cor L\\*a\\*b\\* tem um verdadeiro significado perceptivo.\n",
    "\n",
    "A adição do significado perceptivo torna o espaço de cores L\\*a\\*b\\* menos intuitivo do que RGB e HSV, mas é muito usado na visão computacional. Essencialmente, o espaço de cor L\\*a\\*b\\* é um sistema de 3 eixos:\n",
    "\n",
    "![img](https://user-images.githubusercontent.com/14116020/64585131-dc27c280-d36d-11e9-96f9-b5e41b877dcf.png)\n",
    "\n",
    "Onde definimos cada canal abaixo:\n",
    "\n",
    "* **L-channel**: A \"leveza\" do pixel. Esse valor se movimenta para cima e para baixo no eixo vertical, branco a preto, com tons de cinza neutros no centro do eixo.\n",
    "\n",
    "\n",
    "* **a-channel**: origina-se do centro do canal L e define verde puro em uma extremidade do espectro e vermelho puro no outro.\n",
    "\n",
    "\n",
    "* **b-channel**: também se origina a partir do centro do canal L, mas é perpendicular ao canal a. O canal b define o azul puro em um do espectro e amarelo puro no outro.\n",
    "\n",
    "E uma vez que a distância entre cores entre tem um verdadeiro significado perceptivo, nos permite superar vários problemas de condição de iluminação. Ele também serve como um poderoso descritor de imagem colorida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
