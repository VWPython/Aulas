{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Tracking em vídeos\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color tracking é o processo de identificar na câmera uma ou mais cores e seguir esta cor ao longo do vídeo.\n",
    "\n",
    "Para alcançar este objetivo fazemos a leitura do vídeo da webcam por frame e passamos o frame para uma função detect(), que encontra os valores de pixel que se situam no intervalo de amarelo (poderia ser qualquer cor). Então o atributo lower_range define o limite inferior para a cor que queremos detectar e o atributo upper_range define o limite superior. Usamos a função inRange() para encontrar os pixels dentro do intervalo de valores de pixels definidos por lower_range e upper_range. Ele retorna uma imagem limiar e usamos isso para calcular as coordenadas da região detectada.\n",
    "\n",
    "Para encontrar as coordenadas, podemos usar momentos de imagem. Um momento de imagem é definido como:\n",
    "\n",
    "![img1](https://user-images.githubusercontent.com/14116020/56011085-70f19b80-5cbc-11e9-9f5f-b83f9fa555c8.png)\n",
    "\n",
    "Usando esta regra, podemos calcular as coordenadas x e y usando as seguintes fórmulas:\n",
    "\n",
    "![img2](https://user-images.githubusercontent.com/14116020/56011086-718a3200-5cbc-11e9-9228-797f2daea57b.png)\n",
    "\n",
    "Depois de calcular as coordenadas, a função detect() retorna essas coordenadas e, em seguida, usamos essas coordenadas para desenhar uma linha usando a função cv2.line(), que mostra o caminho da cor no vídeo.\n",
    "\n",
    "Colortracking  nem  sempre  é  muito  preciso.  Pode  funcionar  mal  em  ambientes  de iluminação em constante mudança. Para enfrentar este problema, podemos usar métodos mais sofisticados  de  rastreamento  de  objetos  que  usam  o  conceito  de  movimento  para  rastrear objeto sem vídeos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Cor Amarela\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img):\n",
    "    lower_range = np.array([40, 150, 150], dtype = \"uint8\")\n",
    "    upper_range = np.array([70,255,255], dtype = \"uint8\")\n",
    "    \n",
    "    # Range\n",
    "    img = cv.inRange(img, lower_range, upper_range)\n",
    "    cv.imshow(\"Range\", img)\n",
    "    \n",
    "    # Momento da imagem\n",
    "    momento = cv.moments(img)\n",
    "    \n",
    "    if (momento[\"m00\"] != 0):\n",
    "        x = int(momento[\"m10\"] / momento[\"m00\"])\n",
    "        y = int(momento[\"m01\"] / momento[\"m00\"])\n",
    "    else:\n",
    "        x = 0\n",
    "        y = 0\n",
    "        \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_x = 0\n",
    "last_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (camera.isOpened()):\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    curva_x, curva_y = detect(frame)\n",
    "    cv.line(frame, (curva_x,curva_y), (last_x, last_y), (0,0,200), 5);\n",
    "    last_x = curva_x\n",
    "    last_y = curva_y\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Cor Azul\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre a câmera\n",
    "camera = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Captura cada frame\n",
    "    _, frame = camera.read()\n",
    "\n",
    "    # Converte de BGR para HSV\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)  \n",
    "    \n",
    "    # Coordenadas\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    lower_green = np.array([50,50,50])             \n",
    "    upper_green = np.array([70,255,255])\n",
    "\n",
    "    lower_red = np.array([0, 50, 50])             \n",
    "    upper_red = np.array([10, 255, 255])\n",
    "\n",
    "    # Threshold da image HSV para obter apenas a cor azul\n",
    "    mask_blue = cv.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Threshold da image HSV para obter apenas a cor verde\n",
    "    mask_green = cv.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # Threshold da image HSV para obter apenas a cor vermelha\n",
    "    mask_red = cv.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Bitwise-AND mask e imagem original \n",
    "    res_blue = cv.bitwise_and(frame, frame, mask=mask_blue)\n",
    "    res_green = cv.bitwise_and(frame, frame, mask=mask_green)\n",
    "    res_red = cv.bitwise_and(frame, frame, mask=mask_red)\n",
    "\n",
    "\n",
    "    # Mostra a captura\n",
    "\n",
    "    #cv.imshow('Original', frame)\n",
    "    #cv.imshow('Mask_BLUE', mask_blue)\n",
    "    #cv.imshow('Result Blue', res_blue)\n",
    "    #cv.imshow('Mask_GREEN', mask_green)\n",
    "    #cv.imshow('Result GREEN', res_green)\n",
    "    cv.imshow('Mask_RED', mask_red)\n",
    "    cv.imshow('Result RED', res_red)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "camera.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
