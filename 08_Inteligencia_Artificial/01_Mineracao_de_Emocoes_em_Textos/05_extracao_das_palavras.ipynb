{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração das palavras\n",
    "***\n",
    "\n",
    "Agora iremo criar a tabela de palavras (radicais) para começar o aprendizado de máquina, para montar uma tabela igual a tabela abaixo:\n",
    "\n",
    "![img2](https://user-images.githubusercontent.com/14116020/50458587-48cb7000-094b-11e9-8757-d4b03e19acd0.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import base\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_stemming(texto):\n",
    "    \"\"\"\n",
    "    Pega os radicais do texto\n",
    "    \"\"\"\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    \n",
    "    # Pegar o stemmer especifico para a lingua portuguesa\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frases = []\n",
    "    \n",
    "    for (palavras, emocao) in texto:\n",
    "        # stem() retira o radical da palavra\n",
    "        stemming = [str(stemmer.stem(palavra)) for palavra in palavras.split() if palavra not in stopwords]\n",
    "        frases.append((stemming, emocao))\n",
    "        \n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = aplicar_stemming(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admir', 'muit'], 'alegria'), (['sint', 'complet', 'am'], 'alegria'), (['am', 'maravilh'], 'alegria'), (['sent', 'anim', 'nov'], 'alegria'), (['bem', 'hoj'], 'alegria'), (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'), (['dia', 'bonit'], 'alegria'), (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'), (['am', 'lind'], 'alegria'), (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'), (['amedront'], 'medo'), (['ameac', 'dia'], 'medo'), (['deix', 'apavor'], 'medo'), (['lug', 'apavor'], 'medo'), (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'), (['tom', 'cuid', 'lobisom'], 'medo'), (['descobr', 'encrenc'], 'medo'), (['trem', 'med'], 'medo'), (['med'], 'medo'), (['med', 'result', 'test'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_palavras(stemming):\n",
    "    \"\"\"\n",
    "    Pega a stemming e retira as emoções, pegando só as palavras.\n",
    "    \"\"\"\n",
    "    \n",
    "    so_palavras = []\n",
    "    \n",
    "    for (palavras, emocao) in stemming:\n",
    "        # extend: Pega os elementos da lista e joga 1 por 1 dentro da outra lista\n",
    "        so_palavras.extend(palavras)\n",
    "        \n",
    "    # pega a frequencia de vezes que uma palavra aparece.\n",
    "    qtd_palavras = nltk.FreqDist(so_palavras)\n",
    "    \n",
    "    # Retira as palavras repetidas\n",
    "    sem_repeticao = qtd_palavras.keys()\n",
    "    \n",
    "    return list(sem_repeticao), qtd_palavras.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_unicas, qtd_palavras = busca_palavras(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "['bel', 'nov', 'sint', 'encrenc', 'amizad', 'sent', 'cont', 'pav', 'deix', 'result', 'muit', 'dur', 'cuid', 'jog', 'bem', 'lug', 'fiz', 'carr', 'complet', 'tom', 'hoj', 'vai', 'test', 'admir', 'ont', 'outr', 'trem', 'lobisom', 'bonit', 'perd', 'am', 'maravilh', 'dirig', 'lind', 'amedront', 'elimin', 'sempr', 'med', 'ameac', 'anim', 'dia', 'apavor', 'descobr']\n"
     ]
    }
   ],
   "source": [
    "print(len(palavras_unicas))\n",
    "print(palavras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('am', 4), ('dia', 4), ('med', 3), ('nov', 2), ('deix', 2), ('result', 2), ('test', 2), ('apavor', 2), ('bel', 1), ('sint', 1), ('encrenc', 1), ('amizad', 1), ('sent', 1), ('cont', 1), ('pav', 1), ('muit', 1), ('dur', 1), ('cuid', 1), ('jog', 1), ('bem', 1), ('lug', 1), ('fiz', 1), ('carr', 1), ('complet', 1), ('tom', 1), ('hoj', 1), ('vai', 1), ('admir', 1), ('ont', 1), ('outr', 1), ('trem', 1), ('lobisom', 1), ('bonit', 1), ('perd', 1), ('maravilh', 1), ('dirig', 1), ('lind', 1), ('amedront', 1), ('elimin', 1), ('sempr', 1), ('ameac', 1), ('anim', 1), ('descobr', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(qtd_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_palavras(novas_palavras):\n",
    "    \"\"\"\n",
    "    Recebe uma nova frase (lista de radicais) e verifica quais palavras tem\n",
    "    e quais não tem de acordo com a tabela de palavras unicas (radicais).\n",
    "    Monta uma linha da tabela.\n",
    "    \"\"\"\n",
    "    \n",
    "    frase = set(novas_palavras)\n",
    "    \n",
    "    linha_tabela = {}\n",
    "    \n",
    "    # essa palavras_unicas vem de busca_palavras(stemming)\n",
    "    for palavra in palavras_unicas:\n",
    "        linha_tabela[\"%s\" % palavra] = (palavra in frase)\n",
    "        \n",
    "    return linha_tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bel': False, 'nov': True, 'sint': False, 'encrenc': False, 'amizad': False, 'sent': False, 'cont': False, 'deix': False, 'result': False, 'muit': False, 'dur': False, 'cuid': False, 'lobisom': False, 'pav': False, 'lug': False, 'fiz': False, 'carr': False, 'complet': False, 'hoj': False, 'vai': False, 'test': False, 'admir': False, 'dia': True, 'bem': False, 'jog': False, 'trem': False, 'outr': False, 'bonit': False, 'apavor': False, 'am': True, 'maravilh': False, 'dirig': False, 'lind': False, 'amedront': False, 'elimin': False, 'sempr': False, 'descobr': False, 'med': False, 'tom': False, 'anim': False, 'ont': False, 'perd': False, 'ameac': False}\n"
     ]
    }
   ],
   "source": [
    "print(extrair_palavras(['am', 'nov', 'dia']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair todas as frases (montar a tabela completa)\n",
    "# Vamos pegar cada uma das frases do steamming e aplicar no método extrair_palavras\n",
    "# e jogar tudo para uma variável\n",
    "base_completa = nltk.classify.apply_features(extrair_palavras, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'bel': False, 'nov': False, 'sint': False, 'encrenc': False, 'amizad': False, 'sent': False, 'cont': False, 'deix': False, 'result': False, 'muit': False, 'dur': False, 'cuid': True, 'lobisom': True, 'pav': False, 'lug': False, 'fiz': False, 'carr': False, 'complet': False, 'hoj': False, 'vai': False, 'test': False, 'admir': False, 'dia': False, 'bem': False, 'jog': False, 'trem': False, 'outr': False, 'bonit': False, 'apavor': False, 'am': False, 'maravilh': False, 'dirig': False, 'lind': False, 'amedront': False, 'elimin': False, 'sempr': False, 'descobr': False, 'med': False, 'tom': True, 'anim': False, 'ont': False, 'perd': False, 'ameac': False}, 'medo')\n"
     ]
    }
   ],
   "source": [
    "# Base de dados final que vamos submeter para os algoritmos de aprendizagem de máquina\n",
    "print(base_completa[15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
