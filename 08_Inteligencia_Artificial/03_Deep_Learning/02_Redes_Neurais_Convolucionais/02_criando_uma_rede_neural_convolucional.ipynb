{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma rede neural convolucional\n",
    "***\n",
    "\n",
    "Neste tutorial iremos criar uma rede neural convolucional para detecção de gatos e cachorros\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Saída é uma matriz de caracteristicas\n",
    "# Imagem (h * w * d) = (64 * 64 * 3) = 12.288 neuronios\n",
    "# Filtro (fh * fw * fd) = (3 * 3 * 1) = 9 neuronios\n",
    "# Matriz de caracteristicas (h - fh + 1) x (w - fw + 1) x 1 = (64 - 3 + 1) x (64 - 3 + 1) = 62 x 62 = 3.844 neuronios\n",
    "dimensoes_do_kernel = (3, 3) # matriz 3x3\n",
    "dimensoes_da_imagem = (64, 64, 3) # (largura, altura, canais rgb)\n",
    "classificador.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vai acelerar o processamento, ou seja, vai pegar o mapa de caracteristicas\n",
    "# e vai normaliza os valores em uma escala entre 0 e 1\n",
    "classificador.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para pegar o maior valor do mapa de caracteristicas, realçando-as.\n",
    "# Matriz de caracteristica (h x w x d) = 62 x 62 x 1 = 3.844 neuronios\n",
    "# Pooling Matrix (ph x pw x pd) = 2 x 2 x 1 = 4\n",
    "# Matriz de características realçadas (h/ph x w/pw x d/pd) = 31 x 31 x 1 = 961 neuronios\n",
    "matriz_de_pooling = (2, 2) # matriz 2x2\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando outra camada de convolução\n",
    "classificador.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o flattening para vetorizar a matriz para entrar na rede neural densa\n",
    "classificador.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a primeira camada da rede neural densa (camada de entrada).\n",
    "# UNITS = Quantidade de neuronios que farão parte da camada ((neuronios + 1)/2)\n",
    "# ACTIVATION = Função de ativação\n",
    "# KERNEL_INITIALIZER = Como você vai fazer a inicialização dos pesos\n",
    "classificador.add(Dense(\n",
    "    units = int((961+1)/2),\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a primeira camada oculta da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = int((961+1)/2),\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a camada de saída da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos compilar a rede neural\n",
    "classificador.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens a partir das imagens existentes\n",
    "normalizacao = 1./255\n",
    "# ROTATION_RANGE = Grau de rotação da imagem\n",
    "# HORIZONTAL_FLIP = Vai fazer giros horizontais nas imagens\n",
    "# SHEAR_RANGE = Faz a mudança dos pixels para outra direção\n",
    "# HEIGHT_SHIFT_RANGE = Faixa de mudança da altura da imagem\n",
    "# ZOOM_RANGE = Faixa de mudança do zoom da imagem\n",
    "gerador_de_imagens = ImageDataGenerator(\n",
    "    rescale = normalizacao,\n",
    "    rotation_range = 7,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.07,\n",
    "    zoom_range = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens de teste a partir das imagens existentes\n",
    "gerador_de_imagens_teste = ImageDataGenerator(rescale = normalizacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/training_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-76ab9d31b3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/training_set'"
     ]
    }
   ],
   "source": [
    "# Criar a base de dados de treinamento\n",
    "# TARGET_SIZE = Tamanho das imagens (altura, largura)\n",
    "# BATCH_SIZE = De quantas em quantas imagens será feito o treinamento (de 125 em 125 no caso) - 4000/32 = 125\n",
    "# CLASS_MODE = Tipo de saída, no caso é binario\n",
    "base_treinamento = gerador_de_imagens.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    " # Criar a base de dados de teste\n",
    "# BATCH_SIZE = De quantas em quantas imagens será feito o teste (de 31 em 31 no caso) - 1000/32 = 31\n",
    "base_teste = gerador_de_imagens_teste.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irá salvar o modelo a cada ciclo (epoch) e armazenar o melhor\n",
    "# FILEPATH = Nome do modelo salvo a cada ciclo\n",
    "# MONITOR = Atributo que será monitorado\n",
    "# SAVE_BEST_ONLY = Salva somente os melhores resultados, não os deixando ser sobrescritos por outros\n",
    "# SAVE_WEIGHTS_ONLY = Salvar somente os pesos do modelo (model.save_weights(filepath))\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre o checkpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"melhores_pesos.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir a taxa de treinamento quando as métricas pararem de subir (evoluir)\n",
    "# MONITOR = Atributo que será monitorado no treinamento\n",
    "# FACTOR = Fator que irá reduzir a taxa de aprendizagem (new_lr = lr * factor)\n",
    "# PATIENCE = Se ocorrer 2 vezes a não evolução da métricas reduzir o lr\n",
    "# MIN_LR = Menor taxa de aprendizado que deve chegar\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre a redução da taxa de aprendizado\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    min_lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o treinamento quando o mesmo não evolui mais\n",
    "# MONITOR = Atributo que será monitorado no treinamento\n",
    "# PATIENCE = Quantidade de vezes que deve ocorrer a não evolução até parar\n",
    "# RESTORE_BEST_WEIGHTS = Restaura os melhores pesos que ocorreram no treinamento.\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre a parada do treinamento\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.8190 - acc: 0.5870 - val_loss: 0.8012 - val_acc: 0.5880\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.6702 - acc: 0.6250 - val_loss: 0.7039 - val_acc: 0.5880\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 39s 311ms/step - loss: 0.6154 - acc: 0.6598 - val_loss: 0.6440 - val_acc: 0.6060\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 35s 282ms/step - loss: 0.6005 - acc: 0.6733 - val_loss: 0.5899 - val_acc: 0.6800\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5773 - acc: 0.6950 - val_loss: 0.8552 - val_acc: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a007cb630>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer o treinamento\n",
    "# STEPS_PER_EPOCH = Quantidade de imagens que será treinada por ciclo, ideal o total de imagens\n",
    "# EPOCHS = Quantidade de ciclos que será treinado, quanto maior melhor\n",
    "# VALIDATION_DATA = Imagens de teste\n",
    "# VALIDATION_STEPS = Quantidade de imagens de teste por ciclo\n",
    "classificador.fit_generator(\n",
    "    base_treinamento,\n",
    "    steps_per_epoch = 4000/32,\n",
    "    epochs = 5,\n",
    "    validation_data = base_teste,\n",
    "    validation_steps = 1000/32,\n",
    "    callbacks=[checkpointer, reduce_learning_rate, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a estrutura da rede neural\n",
    "classificador_json = classificador.to_json()\n",
    "with open('classificador.json', 'w') as json_file:\n",
    "    json_file.write(classificador_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os pesos da rede neural (pip install h5py)\n",
    "classificador.save_weights('pesos.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando a estrutura da rede neural\n",
    "with open('classificador.json', 'r') as json_file:\n",
    "    estrutura = json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o classificador\n",
    "classificador_externo = model_from_json(estrutura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os pesos da rede neural\n",
    "classificador_externo.load_weights('melhores_pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste = image.load_img('dataset/test_set/gato/cat.3500.jpg', target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste_array = image.img_to_array(imagem_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização\n",
    "imagem_teste_array /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatar para o formato do tensorFlow (qtd, largura, altura, canais)\n",
    "imagem_teste_array = np.expand_dims(imagem_teste_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = classificador_externo.predict(imagem_teste_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gato': 1, 'cachorro': 0}\n"
     ]
    }
   ],
   "source": [
    "print(base_treinamento.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54427975]]\n",
      "É um gato\n"
     ]
    }
   ],
   "source": [
    "# 0 < previsao < 0.5 = Cachorro\n",
    "# 0.5 <= previsao < 1 = Gato\n",
    "print(previsao)\n",
    "if previsao >= 0.5:\n",
    "    print(\"É um gato\")\n",
    "else:\n",
    "    print(\"É um cachorro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
