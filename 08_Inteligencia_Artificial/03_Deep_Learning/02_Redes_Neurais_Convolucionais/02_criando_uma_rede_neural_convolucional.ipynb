{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma rede neural convolucional\n",
    "***\n",
    "\n",
    "Neste tutorial iremos criar uma rede neural convolucional para detecção de gatos e cachorros\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "qtd_filtros = 32 # Recomendado é 64\n",
    "dimensoes_do_kernel = (3, 3) # matriz 3x3\n",
    "dimensoes_da_imagem = (64, 64, 3) # (largura, altura, canais rgb)\n",
    "classificador.add(Conv2D(\n",
    "    qtd_filtros,\n",
    "    dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vai acelerar o processamento, ou seja, vai pegar o mapa de caracteristicas\n",
    "# e vai normaliza os valores em uma escala entre 0 e 1\n",
    "classificador.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para pegar o maior valor do mapa de caracteristicas, realçando-as.\n",
    "matriz_de_pooling = (2, 2) # matriz 2x2\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando outra camada de convolução\n",
    "classificador.add(Conv2D(\n",
    "    qtd_filtros,\n",
    "    dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o flattening para vetorizar a matriz para entrar na rede neural densa\n",
    "classificador.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a primeira camada da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = 128,\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a primeira camada oculta da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = 128,\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a camada de saída da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos compilar a rede neural\n",
    "classificador.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens a partir das imagens existentes\n",
    "normalizacao = 1./255\n",
    "# ROTATION_RANGE = Grau de rotação da imagem\n",
    "# HORIZONTAL_FLIP = Vai fazer giros horizontais nas imagens\n",
    "# SHEAR_RANGE = Faz a mudança dos pixels para outra direção\n",
    "# HEIGHT_SHIFT_RANGE = Faixa de mudança da altura da imagem\n",
    "# ZOOM_RANGE = Faixa de mudança do zoom da imagem\n",
    "gerador_de_imagens = ImageDataGenerator(\n",
    "    rescale = normalizacao,\n",
    "    rotation_range = 7,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.07,\n",
    "    zoom_range = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens de teste a partir das imagens existentes\n",
    "gerador_de_imagens_teste = ImageDataGenerator(rescale=normalizacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criar a base de dados de treinamento\n",
    "# TARGET_SIZE = Tamanho das imagens\n",
    "# BATCH_SIZE = De quantas em quantas imagens será feito o treinamento\n",
    "# CLASS_MODE = Tipo de saída, no caso é binario\n",
    "base_treinamento = gerador_de_imagens.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criar a base de dados de teste\n",
    "base_teste = gerador_de_imagens_teste.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.8190 - acc: 0.5870 - val_loss: 0.8012 - val_acc: 0.5880\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.6702 - acc: 0.6250 - val_loss: 0.7039 - val_acc: 0.5880\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 39s 311ms/step - loss: 0.6154 - acc: 0.6598 - val_loss: 0.6440 - val_acc: 0.6060\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 35s 282ms/step - loss: 0.6005 - acc: 0.6733 - val_loss: 0.5899 - val_acc: 0.6800\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5773 - acc: 0.6950 - val_loss: 0.8552 - val_acc: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a007cb630>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer o treinamento\n",
    "# STEPS_PER_EPOCH = Quantidade de imagens que será treinada por ciclo, ideal o total de imagens\n",
    "# EPOCHS = Quantidade de ciclos que será treinado, quanto maior melhor\n",
    "# VALIDATION_DATA = Imagens de teste\n",
    "# VALIDATION_STEPS = Quantidade de imagens de teste por ciclo\n",
    "classificador.fit_generator(\n",
    "    base_treinamento,\n",
    "    steps_per_epoch = 4000/32,\n",
    "    epochs = 5,\n",
    "    validation_data = base_teste,\n",
    "    validation_steps = 1000/32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a estrutura da rede neural\n",
    "classificador_json = classificador.to_json()\n",
    "with open('classificador.json', 'w') as json_file:\n",
    "    json_file.write(classificador_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os pesos da rede neural (pip install h5py)\n",
    "classificador.save_weights('classificador.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando a estrutura da rede neural\n",
    "with open('classificador.json', 'r') as json_file:\n",
    "    estrutura = json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o classificador\n",
    "classificador_externo = model_from_json(estrutura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os pesos da rede neural\n",
    "classificador_externo.load_weights('classificador.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste = image.load_img('dataset/test_set/gato/cat.3500.jpg', target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste_array = image.img_to_array(imagem_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização\n",
    "imagem_teste_array /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatar para o formato do tensorFlow (qtd, largura, altura, canais)\n",
    "imagem_teste_array = np.expand_dims(imagem_teste_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = classificador_externo.predict(imagem_teste_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gato': 1, 'cachorro': 0}\n"
     ]
    }
   ],
   "source": [
    "print(base_treinamento.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54427975]]\n",
      "É um gato\n"
     ]
    }
   ],
   "source": [
    "# 0 < previsao < 0.5 = Cachorro\n",
    "# 0.5 <= previsao < 1 = Gato\n",
    "print(previsao)\n",
    "if previsao >= 0.5:\n",
    "    print(\"É um gato\")\n",
    "else:\n",
    "    print(\"É um cachorro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
