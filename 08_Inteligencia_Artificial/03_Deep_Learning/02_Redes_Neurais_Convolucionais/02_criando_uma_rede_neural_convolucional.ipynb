{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma rede neural convolucional\n",
    "***\n",
    "\n",
    "Neste tutorial iremos criar uma rede neural convolucional para detecção de gatos e cachorros\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saída é uma matriz de caracteristicas\n",
    "# Imagem (h * w * d) = (64 * 64 * 3) = 12.288 neuronios\n",
    "# Filtro (fh * fw * fd) = (3 * 3 * 1) = 9 neuronios\n",
    "# Matriz de caracteristicas (h - fh + 1) x (w - fw + 1) x 1 = (64 - 3 + 1) x (64 - 3 + 1) = 62 x 62 = 3.844 neuronios\n",
    "dimensoes_do_kernel = (3, 3) # matriz 3x3\n",
    "dimensoes_da_imagem = (64, 64, 3) # (largura, altura, canais rgb)\n",
    "classificador.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vai acelerar o processamento, ou seja, vai pegar o mapa de caracteristicas\n",
    "# e vai normaliza os valores em uma escala entre 0 e 1\n",
    "classificador.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para pegar o maior valor do mapa de caracteristicas, realçando-as.\n",
    "# Matriz de caracteristica (h x w x d) = 62 x 62 x 1 = 3.844 neuronios\n",
    "# Pooling Matrix (ph x pw x pd) = 2 x 2 x 1 = 4\n",
    "# Matriz de características realçadas (h/ph x w/pw x d/pd) = 31 x 31 x 1 = 961 neuronios\n",
    "matriz_de_pooling = (2, 2) # matriz 2x2\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando outra camada de convolução\n",
    "classificador.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = dimensoes_do_kernel,\n",
    "    input_shape = dimensoes_da_imagem,\n",
    "    activation = 'relu'\n",
    "))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size = matriz_de_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o flattening para vetorizar a matriz para entrar na rede neural densa\n",
    "classificador.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a primeira camada da rede neural densa (camada de entrada).\n",
    "# UNITS = Quantidade de neuronios que farão parte da camada ((neuronios + 1)/2)\n",
    "# ACTIVATION = Função de ativação\n",
    "# KERNEL_INITIALIZER = Como você vai fazer a inicialização dos pesos\n",
    "classificador.add(Dense(\n",
    "    units = int((961+1)/2),\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a primeira camada oculta da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = int((961+1)/2),\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos zerar 20% dos valores de entrada para evitar o overfitting\n",
    "classificador.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar a camada de saída da rede neural densa\n",
    "classificador.add(Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos compilar a rede neural\n",
    "classificador.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens a partir das imagens existentes\n",
    "normalizacao = 1./255\n",
    "# ROTATION_RANGE = Grau de rotação da imagem\n",
    "# HORIZONTAL_FLIP = Vai fazer giros horizontais nas imagens\n",
    "# SHEAR_RANGE = Faz a mudança dos pixels para outra direção\n",
    "# HEIGHT_SHIFT_RANGE = Faixa de mudança da altura da imagem\n",
    "# ZOOM_RANGE = Faixa de mudança do zoom da imagem\n",
    "gerador_de_imagens = ImageDataGenerator(\n",
    "    rescale = normalizacao,\n",
    "    rotation_range = 7,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.07,\n",
    "    zoom_range = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria novas imagens de teste a partir das imagens existentes\n",
    "gerador_de_imagens_teste = ImageDataGenerator(rescale = normalizacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criar a base de dados de treinamento\n",
    "# TARGET_SIZE = Tamanho das imagens (altura, largura)\n",
    "# BATCH_SIZE = De quantas em quantas imagens será feito o treinamento (de 125 em 125 no caso) - 4000/32 = 125\n",
    "# CLASS_MODE = Tipo de saída, no caso é binario\n",
    "base_treinamento = gerador_de_imagens.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    " # Criar a base de dados de teste\n",
    "# BATCH_SIZE = De quantas em quantas imagens será feito o teste (de 31 em 31 no caso) - 1000/32 = 31\n",
    "base_teste = gerador_de_imagens_teste.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irá salvar o modelo a cada ciclo (epoch) e armazenar o melhor\n",
    "# FILEPATH = Nome do modelo salvo a cada ciclo\n",
    "# MONITOR = Atributo que será monitorado\n",
    "# SAVE_BEST_ONLY = Salva somente os melhores resultados, não os deixando ser sobrescritos por outros\n",
    "# SAVE_WEIGHTS_ONLY = Salvar somente os pesos do modelo (model.save_weights(filepath))\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre o checkpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"melhores_pesos.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir a taxa de treinamento quando as métricas pararem de subir (evoluir)\n",
    "# MONITOR = Atributo que será monitorado no treinamento\n",
    "# FACTOR = Fator que irá reduzir a taxa de aprendizagem (new_lr = lr * factor)\n",
    "# PATIENCE = Se ocorrer 2 vezes a não evolução da métricas reduzir o lr\n",
    "# MIN_LR = Menor taxa de aprendizado que deve chegar\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre a redução da taxa de aprendizado\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    min_lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o treinamento quando o mesmo não evolui mais\n",
    "# MONITOR = Atributo que será monitorado no treinamento\n",
    "# PATIENCE = Quantidade de vezes que deve ocorrer a não evolução até parar\n",
    "# RESTORE_BEST_WEIGHTS = Restaura os melhores pesos que ocorreram no treinamento.\n",
    "# VERBOSE = Aparecer na tela feedbacks sobre a parada do treinamento\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 63s 504ms/step - loss: 0.8629 - accuracy: 0.5878 - val_loss: 3.3054 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.30539, saving model to melhores_pesos.h5\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 80s 641ms/step - loss: 0.6558 - accuracy: 0.6442 - val_loss: 1.2180 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.30539 to 1.21805, saving model to melhores_pesos.h5\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 75s 599ms/step - loss: 0.6131 - accuracy: 0.6695 - val_loss: 2.7239 - val_accuracy: 0.5170\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.21805\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.5875 - accuracy: 0.6945 - val_loss: 0.4869 - val_accuracy: 0.5530\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21805 to 0.48694, saving model to melhores_pesos.h5\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 53s 421ms/step - loss: 0.5490 - accuracy: 0.7272 - val_loss: 0.1942 - val_accuracy: 0.6290\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48694 to 0.19423, saving model to melhores_pesos.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe3b02a3690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer o treinamento\n",
    "# STEPS_PER_EPOCH = Quantidade de imagens que será treinada por ciclo, ideal o total de imagens\n",
    "# EPOCHS = Quantidade de ciclos que será treinado, quanto maior melhor\n",
    "# VALIDATION_DATA = Imagens de teste\n",
    "# VALIDATION_STEPS = Quantidade de imagens de teste por ciclo\n",
    "classificador.fit_generator(\n",
    "    base_treinamento,\n",
    "    steps_per_epoch = 4000/32,\n",
    "    epochs = 5,\n",
    "    validation_data = base_teste,\n",
    "    validation_steps = 1000/32,\n",
    "    callbacks=[checkpointer, reduce_learning_rate, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a estrutura da rede neural\n",
    "classificador_json = classificador.to_json()\n",
    "with open('classificador.json', 'w') as json_file:\n",
    "    json_file.write(classificador_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os pesos da rede neural (pip install h5py)\n",
    "classificador.save_weights('pesos.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando a estrutura da rede neural\n",
    "with open('classificador.json', 'r') as json_file:\n",
    "    estrutura = json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o classificador\n",
    "classificador_externo = model_from_json(estrutura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os pesos da rede neural\n",
    "classificador_externo.load_weights('melhores_pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste = image.load_img('dataset/test_set/gato/cat.3500.jpg', target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste_array = image.img_to_array(imagem_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização\n",
    "imagem_teste_array /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatar para o formato do tensorFlow (qtd, largura, altura, canais)\n",
    "imagem_teste_array = np.expand_dims(imagem_teste_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = classificador_externo.predict(imagem_teste_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cachorro': 0, 'gato': 1}\n"
     ]
    }
   ],
   "source": [
    "print(base_treinamento.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47291747]]\n",
      "É um cachorro\n"
     ]
    }
   ],
   "source": [
    "# 0 < previsao < 0.5 = Cachorro\n",
    "# 0.5 <= previsao < 1 = Gato\n",
    "print(previsao)\n",
    "if previsao >= 0.5:\n",
    "    print(\"É um gato\")\n",
    "else:\n",
    "    print(\"É um cachorro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
